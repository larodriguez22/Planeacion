{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graphics():\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Graphics module ready!\")\n",
    "        \n",
    "    def render(self,x_fin,y_fin, x, y, environment, plot_values = True):\n",
    "            \n",
    "        fig1 = plt.figure(figsize=(4, 4))\n",
    "        ax1 = fig1.add_subplot(111, aspect='equal')\n",
    "\n",
    "        # Horizontal lines.\n",
    "        for i in range(0, 6):\n",
    "            ax1.axhline(i * 0.2, linewidth=2, color=\"#2D2D33\")\n",
    "            ax1.axvline(i * 0.2, linewidth=2, color=\"#2D2D33\")\n",
    "\n",
    "        # Salida, Meta & GameOver.\n",
    "        # Salida (amarillos)\n",
    "        ax1.add_patch(patches.Rectangle((0.0, 0.0), 0.2, 0.2, facecolor = \"#F6D924\"))\n",
    "        \n",
    "        ax1.add_patch(patches.Rectangle((0.2, 0.8), 0.2, 0.2, facecolor = \"#F6D924\"))\n",
    "        ax1.add_patch(patches.Rectangle((0.8, 0.2), 0.2, 0.2, facecolor = \"#F6D924\"))\n",
    "        \n",
    "        # Meta (verde)\n",
    "        ax1.add_patch(patches.Rectangle((x_fin,y_fin), 0.2, 0.2, facecolor = \"#68FF33\"))\n",
    "        #ax1.add_patch(patches.Rectangle((0.8, 0.8), 0.2, 0.2, facecolor = \"#FF5533\"))\n",
    "        \n",
    "        # Muros del juego.\n",
    "        array=[[0.8, 0.6],[0.2, 0.4],[0.6, 0.2],[0.2, 0.0],[0.4, 0.8],[0.8, 0.4]]\n",
    "        while len(array)!=0:\n",
    "            var2 = array.pop(0)\n",
    "            x_ = var2[0]\n",
    "            y_ = var2[1]\n",
    "            ax1.add_patch(patches.Rectangle((x_,y_), 0.2, 0.2, facecolor = \"#33A4FF\"))\n",
    "        #ax1.add_patch(patches.Rectangle((0.6, 0.2), 0.2, 0.2, facecolor = \"#33A4FF\"))\n",
    "        #ax1.add_patch(patches.Rectangle((0.2, 0.0), 0.2, 0.2, facecolor = \"#33A4FF\"))\n",
    "        \n",
    "        #ax1.add_patch(patches.Rectangle((0.4, 0.8), 0.2, 0.2, facecolor = \"#33A4FF\"))\n",
    "        #ax1.add_patch(patches.Rectangle((0.4, 0.8), 0.2, 0.2, facecolor = \"#33A4FF\"))\n",
    "        #ax1.add_patch(patches.Rectangle((0.8, 0.4), 0.2, 0.2, facecolor = \"#33A4FF\"))\n",
    "        \n",
    "        # Limit grid view.\n",
    "        plt.ylim((0, 1))\n",
    "        plt.xlim((0, 1))\n",
    "\n",
    "        # Plot player.\n",
    "        plt.scatter(x, y, s = 100, color = \"black\", marker = \"o\", facecolor = \"blue\", edgecolors = \"blue\", zorder = 10)\n",
    "\n",
    "        # Plot state values.\n",
    "        if plot_values:\n",
    "            for i in range(0, len(environment.value_state_table)):\n",
    "                for j in range(0, len(environment.value_state_table[0])):\n",
    "                    plt.text(environment.grid_pos[i] - 0.08, environment.grid_pos[j] - 0.03, \n",
    "                             round(environment.value_state_table[i][j], 1), fontsize=16)\n",
    "                \n",
    "        # Plot grid.\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridEnvironment():\n",
    "    \n",
    "    def __init__(self, fin_x, fin_y):\n",
    "        self.fin_x = fin_x\n",
    "        self.fin_y = fin_y\n",
    "        # RECOMPENSA\n",
    "        self.rw = -1 # Living (Movement) Penalty\n",
    "        # INICIALIZACION\n",
    "        self.walls_and_paths = [[1, 1, 1, 1, 1], [0, 1, 0, 0, 1], [1, 1, 1, 1, 0], [1, 0, 1, 1, 1], [1, 1, 0, 1, 1]]\n",
    "        self.rewards = [[self.rw, self.rw, self.rw, self.rw, self.rw], \n",
    "                        [self.rw, self.rw, self.rw, self.rw, self.rw], \n",
    "                        [self.rw, self.rw, self.rw, self.rw, self.rw], \n",
    "                        [self.rw, self.rw, self.rw, self.rw, self.rw], \n",
    "                        [self.rw, self.rw, self.rw, self.rw, self.rw]]\n",
    "        self.grid_pos = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "        # Cambiar el valor\n",
    "        self.value_state_table = [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n",
    "        self.value_state_table[fin_x][fin_y]=100\n",
    "    \n",
    "    def getStateValue(self, position):\n",
    "        return self.value_state_table[position[0]][position[1]]\n",
    "    \n",
    "    def reset(self, fin_x, fin_y):\n",
    "        self.value_state_table = [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n",
    "        self.value_state_table[fin_x][fin_y]=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x  3\n",
      "y  1\n",
      "x  4\n",
      "y  2\n",
      "x  4\n",
      "y  3\n",
      "x  2\n",
      "y  4\n",
      "x  0\n",
      "y  4\n",
      "x final:  0\n",
      "y final:  4\n"
     ]
    }
   ],
   "source": [
    "x_fin=0\n",
    "y_fin=0\n",
    "[0.8, 0.4]\n",
    "while (x_fin==0 and y_fin==0) or (x_fin==1 and y_fin==4) or (x_fin==4 and y_fin==1) or (x_fin==4 and y_fin==3) or (x_fin==1 and y_fin==2) or(x_fin==3 and y_fin==1) or(x_fin==1 and y_fin==0) or(x_fin==2 and y_fin==4) or(x_fin==4 and y_fin==2):\n",
    "    x_fin=random.randint(1, 5)-1\n",
    "    y_fin=random.randint(1, 5)-1\n",
    "    print(\"x \", x_fin)\n",
    "    print(\"y \",y_fin)\n",
    "\n",
    "print(\"x final: \",x_fin)\n",
    "print(\"y final: \",y_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphics module ready!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "environment = GridEnvironment(x_fin,y_fin)\n",
    "graph = Graphics()\n",
    "graph.render(x_fin*0.2,y_fin*0.2, 0.1, 0.1, environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class valueBasedAgent():\n",
    "    \n",
    "    def __init__(self, environment, policy, discount_factor):\n",
    "        self.pos = [0,0]\n",
    "        self.total_reward = 0\n",
    "        self.environment = environment\n",
    "        self.discount_factor = discount_factor\n",
    "        self.actions = [\"up\", \"down\", \"left\", \"right\"]\n",
    "        \n",
    "        # Start with a random policy. 0.25 chance of moving to any direction.\n",
    "        self.policy = policy   \n",
    "            \n",
    "    def forwardState(self, pos, action):\n",
    "        \n",
    "        # New position array.\n",
    "        new_position = pos\n",
    "        \n",
    "        # Compute new position based on action taken.\n",
    "        if(action == \"up\" and pos[1] < 4):\n",
    "            if(self.environment.walls_and_paths[pos[0]][pos[1] + 1]) == 1:\n",
    "                new_position = [pos[0], pos[1] + 1]\n",
    "\n",
    "        elif(action == \"down\" and pos[1] > 0):\n",
    "            if(self.environment.walls_and_paths[pos[0]][pos[1] - 1]) == 1:\n",
    "                new_position = [pos[0], pos[1] - 1]\n",
    "                \n",
    "        elif(action == \"left\" and pos[0] > 0):\n",
    "            if(self.environment.walls_and_paths[pos[0] - 1][pos[1]]) == 1:\n",
    "                new_position = [pos[0] - 1, pos[1]]\n",
    "\n",
    "        elif(action == \"right\" and pos[0] < 4):\n",
    "            if(self.environment.walls_and_paths[pos[0] + 1][pos[1]]) == 1:\n",
    "                new_position = [pos[0] + 1, pos[1]]\n",
    "        return new_position\n",
    "        \n",
    "        \n",
    "    def valueFunction(self):\n",
    "            \n",
    "        # Initialize variable.\n",
    "        new_state_value = 0\n",
    "    \n",
    "        # Random movement! - Cuando aun no se ha inicializado \n",
    "        if self.policy[self.pos[0]][self.pos[1]] == \"r\":\n",
    "            for action in self.actions:        \n",
    "                forward_state = self.forwardState(self.pos, action)\n",
    "                \n",
    "                # Simplified version of Q-value. BELLMANS EQUATION\n",
    "                q_value = (self.environment.rewards[forward_state[0]][forward_state[1]] \n",
    "                                    + self.discount_factor * self.environment.value_state_table[forward_state[0]][forward_state[1]])\n",
    "                new_state_value += q_value * 0.25 # Probabilidad de 0.25 para cada una de las acciones\n",
    "            return new_state_value\n",
    "        \n",
    "        # Not random movement!\n",
    "        else: \n",
    "            action = self.policy[self.pos[0]][self.pos[1]]\n",
    "            forward_state = self.forwardState(self.pos, action)\n",
    "            \n",
    "            # Simplified version of Q-value.\n",
    "            q_value = (self.environment.rewards[forward_state[0]][forward_state[1]] \n",
    "                                    + self.discount_factor * self.environment.value_state_table[forward_state[0]][forward_state[1]])\n",
    "            new_state_value += q_value # Probabilidad de 1\n",
    "            return new_state_value\n",
    "        \n",
    "    def getPosition(self):\n",
    "        return self.pos\n",
    "    \n",
    "    def getReward(self):\n",
    "        return self.total_reward\n",
    "    \n",
    "    def setPosition(self, x, y):\n",
    "        self.pos = [x, y]\n",
    "        \n",
    "    def updateValueStateTable(self):\n",
    "        new_state_value = self.valueFunction()\n",
    "        self.environment.value_state_table[self.pos[0]][self.pos[1]] = new_state_value\n",
    "        \n",
    "    def selectBestAction(self):\n",
    "        \n",
    "        # Compute new possible states.\n",
    "        go_up = self.forwardState(self.pos, \"up\")\n",
    "        go_down = self.forwardState(self.pos, \"down\")\n",
    "        go_left = self.forwardState(self.pos, \"left\")\n",
    "        go_right = self.forwardState(self.pos, \"right\")\n",
    "        \n",
    "        # Q values (simplified version).\n",
    "        up_value = (self.environment.rewards[go_up[0]][go_up[1]] + \n",
    "                    self.discount_factor * self.environment.value_state_table[go_up[0]][go_up[1]])\n",
    "        down_value = (self.environment.rewards[go_down[0]][go_down[1]] + \n",
    "                      self.discount_factor * self.environment.value_state_table[go_down[0]][go_down[1]])\n",
    "        left_value = (self.environment.rewards[go_left[0]][go_left[1]] + \n",
    "                        self.discount_factor * self.environment.value_state_table[go_left[0]][go_left[1]])\n",
    "        right_value = (self.environment.rewards[go_right[0]][go_right[1]] + \n",
    "                       self.discount_factor * self.environment.value_state_table[go_right[0]][go_right[1]])\n",
    "        \n",
    "        # Array of Q-values.\n",
    "        values = [up_value, down_value, left_value, right_value]\n",
    "        \n",
    "        best_action = self.actions[values.index(max(values))] \n",
    "        return best_action       \n",
    "            \n",
    "    def move(self):\n",
    "    \n",
    "        # Select action according to policy.\n",
    "        action = self.policy[self.pos[0]][self.pos[1]]\n",
    "        print(\"Action taken\", action)\n",
    "\n",
    "        # Move to new position according to action taken.\n",
    "        self.pos = self.forwardState(self.pos, action)\n",
    "        print(\"New Position: \", self.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyEvaluation(Graphics):\n",
    "    \n",
    "    def __init__(self,x_fin,y_fin, environment, agent, iterations = 3):\n",
    "        \n",
    "        self.x_fin = x_fin\n",
    "        self.y_fin = y_fin\n",
    "        self.environment = environment       \n",
    "        self.agent = agent                     \n",
    "        #print(\"GridWorld Initialize!\")\n",
    "        self.iterations = iterations\n",
    "    \n",
    "    def evaluate(self, plot_grid = True):\n",
    "        self.DP_policy_evaluation(self.iterations, plot_grid)\n",
    "        \n",
    "    def DP_policy_evaluation(self, iterations, plot_grid):\n",
    "        \n",
    "        for k in range(0, iterations):\n",
    "            for i in range(0, len(self.environment.value_state_table)):\n",
    "                for j in range(0, len(self.environment.value_state_table[0])):\n",
    "\n",
    "                    if self.environment.walls_and_paths[i][j] == 1 and self.canChangeStateValue(i, j):\n",
    "\n",
    "                        # Set agent position.\n",
    "                        self.agent.setPosition(i, j)\n",
    "                        self.agent.updateValueStateTable()\n",
    "\n",
    "                        # Method of the super class.\n",
    "                        if(plot_grid):\n",
    "                            \n",
    "                            # Render game.\n",
    "                            pos = self.agent.getPosition()\n",
    "                            grid_coords = self.environment.grid_pos\n",
    "                            \n",
    "                            self.render(grid_coords[pos[0]], grid_coords[pos[1]], self.environment, True)\n",
    "                            time.sleep(0.01)\n",
    "                            clear_output(wait = True)\n",
    "                            \n",
    "    \n",
    "\n",
    "    def canChangeStateValue(self, x, y):\n",
    "        # Posicion que no se puede modificar\n",
    "        cant_modify = bool((x == self.x_fin and y == self.y_fin)) # or (x == 4 and y == 4))\n",
    "        \n",
    "        grid = self.environment.walls_and_paths\n",
    "        coords = list()\n",
    "        \n",
    "        # Get walls.\n",
    "        for i in range(0, len(grid)):\n",
    "            for j in range(0, len(grid[0])):\n",
    "                if grid[i][j] == 0:\n",
    "                    coords.append([i, j])\n",
    "        for c in coords: \n",
    "            if c == [x, y]:\n",
    "                cant_modify = True\n",
    "                break\n",
    "                \n",
    "        return not cant_modify\n",
    "    \n",
    "    def updatePolicy(self):\n",
    "        \n",
    "         for i in range(0, len(self.environment.value_state_table)):\n",
    "                for j in range(0, len(self.environment.value_state_table[0])):\n",
    "                    if self.environment.walls_and_paths[i][j] == 1:\n",
    "                        \n",
    "                        # Set agent position.\n",
    "                        self.agent.setPosition(i, j)\n",
    "                        best_action = self.agent.selectBestAction()\n",
    "                        self.agent.policy[i][j] = best_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game(Graphics):\n",
    "    \n",
    "    def __init__(self,x_fin,y_fin, environment, agent):\n",
    "        \n",
    "        self.environment = environment       \n",
    "        self.agent = agent             \n",
    "        print(\"GridWorld Initialize!\")\n",
    "                \n",
    "    def update(self, secs):\n",
    "        \n",
    "        pos = self.agent.getPosition()\n",
    "        grid_coords = self.environment.grid_pos\n",
    "        self.render(x_fin*0.2,y_fin*0.2, grid_coords[pos[0]], grid_coords[pos[1]], self.environment, False)\n",
    "        time.sleep(1)\n",
    "        clear_output(wait = True)\n",
    "        # (self.agent.pos[0] == 4 and self.agent.pos[1] == 3)\n",
    "        while not ((self.agent.pos[0] == x_fin and self.agent.pos[1] == y_fin)):\n",
    "            \n",
    "            self.agent.move()\n",
    "            pos = self.agent.getPosition()\n",
    "            print(grid_coords[pos[0]], grid_coords[pos[1]])\n",
    "            self.render(x_fin*0.2,y_fin*0.2, grid_coords[pos[0]], grid_coords[pos[1]], self.environment, False)\n",
    "            \n",
    "            time.sleep(secs)\n",
    "            clear_output(wait = True)\n",
    "            \n",
    "        #self.render(grid_coords[pos[0]], grid_coords[pos[1]], self.environment, False)\n",
    "        #time.sleep(secs)\n",
    "        #print(\"Yuhuu, we won the game!\")\n",
    "        #clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Policy Evaluation (Planning) for DP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['r', 'r', 'r', 'r', 'r'],\n",
       " ['r', 'r', 'r', 'r', 'r'],\n",
       " ['r', 'r', 'r', 'r', 'r'],\n",
       " ['r', 'r', 'r', 'r', 'r'],\n",
       " ['r', 'r', 'r', 'r', 'r']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the random policy.\n",
    "policy = list()\n",
    "for i in range(0, 5):\n",
    "    column = list()\n",
    "    for j in range(0, 5):\n",
    "        column.append(\"r\")\n",
    "    policy.append(column)\n",
    "\n",
    "# Initialize environment and agent.\n",
    "discount_factor = 1\n",
    "environment = GridEnvironment(x_fin,y_fin)\n",
    "agent = valueBasedAgent(environment, policy, discount_factor)\n",
    "\n",
    "agent.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 100],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment.value_state_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize policy evaluation class.\n",
    "policy_evaluation = PolicyEvaluation(x_fin,y_fin,environment, agent, iterations = 100)\n",
    "policy_evaluation.evaluate(plot_grid = False)\n",
    "\n",
    "policy_evaluation.updatePolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['up', 'up', 'up', 'up', 'up'],\n",
       " ['r', 'left', 'r', 'r', 'left'],\n",
       " ['up', 'left', 'down', 'down', 'r'],\n",
       " ['left', 'r', 'left', 'down', 'down'],\n",
       " ['left', 'down', 'r', 'left', 'down']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New agent policy after policy evaluation.\n",
    "agent.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-15.343990227427643,\n",
       "  -12.779752395974478,\n",
       "  21.29092352597624,\n",
       "  58.765116545842005,\n",
       "  100],\n",
       " [0, -41.34137065673502, 0, 0, 95.99999999996922],\n",
       " [-75.2782185795262,\n",
       "  -67.38914703641099,\n",
       "  -82.73368176752383,\n",
       "  -89.36693047617209,\n",
       "  0],\n",
       " [-81.5442818000637,\n",
       "  0,\n",
       "  -89.36693047617209,\n",
       "  -93.96463686119768,\n",
       "  -97.24147056314555],\n",
       " [-85.68928070682048,\n",
       "  -87.75367007065563,\n",
       "  0,\n",
       "  -97.24147056314555,\n",
       "  -98.55901473104177]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment.value_state_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Win the Game with the previous policy evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action taken left\n",
      "New Position:  [0, 4]\n",
      "0.1 0.9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.pos = [1, 4]\n",
    "game = Game(x_fin,y_fin, environment, agent)\n",
    "game.update(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action taken up\n",
      "New Position:  [0, 4]\n",
      "0.1 0.9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.pos = [4, 1]\n",
    "game = Game(x_fin,y_fin,environment, agent)\n",
    "game.update(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action taken up\n",
      "New Position:  [0, 4]\n",
      "0.1 0.9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.pos = [0, 0]\n",
    "game = Game(x_fin,y_fin,environment, agent)\n",
    "game.update(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the random policy.\n",
    "policy = list()\n",
    "for i in range(0, 5):\n",
    "    column = list()\n",
    "    for j in range(0, 5):\n",
    "        column.append(\"r\")\n",
    "    policy.append(column)\n",
    "    \n",
    "# Initaliza environment and agent.\n",
    "discount_factor = 0.5\n",
    "environment = GridEnvironment(x_fin,y_fin)\n",
    "agent = valueBasedAgent(environment, policy, discount_factor)\n",
    "\n",
    "# Policy iteration algorithm.\n",
    "for i in range(0, 1000):\n",
    "\n",
    "    # Reset value function.\n",
    "    environment.reset(x_fin,y_fin)\n",
    "\n",
    "    # Evaluate new policy.\n",
    "    policy_evaluation = PolicyEvaluation(x_fin,y_fin, environment, agent, iterations = 10)\n",
    "    policy_evaluation.evaluate(plot_grid = False)\n",
    "    policy_evaluation.updatePolicy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The optimal policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['up', 'right', 'down', 'down', 'down'],\n",
       " ['r', 'right', 'r', 'r', 'left'],\n",
       " ['up', 'up', 'up', 'right', 'r'],\n",
       " ['left', 'r', 'up', 'up', 'right'],\n",
       " ['left', 'down', 'r', 'up', 'up']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the random policy.\n",
    "policy = list()\n",
    "for i in range(0, 5):\n",
    "    column = list()\n",
    "    for j in range(0, 5):\n",
    "        column.append(\"r\")\n",
    "    policy.append(column)\n",
    "    \n",
    "# Initaliza environment and agent.\n",
    "discount_factor = 0.6\n",
    "environment = GridEnvironment(x_fin,y_fin)\n",
    "agent = valueBasedAgent(environment, policy, discount_factor)\n",
    "\n",
    "# Policy iteration algorithm.\n",
    "for i in range(0, 1000):\n",
    "\n",
    "    # Reset value function.\n",
    "    # environment.reset() => We do not reset the environment? \n",
    "\n",
    "    # Evaluate new policy.\n",
    "    policy_evaluation = PolicyEvaluation(x_fin,y_fin,environment, agent, iterations = 1)\n",
    "    policy_evaluation.evaluate(plot_grid = False)\n",
    "    policy_evaluation.updatePolicy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The optimal policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['up', 'right', 'down', 'down', 'down'],\n",
       " ['r', 'right', 'r', 'r', 'left'],\n",
       " ['up', 'up', 'up', 'right', 'r'],\n",
       " ['left', 'r', 'up', 'up', 'right'],\n",
       " ['left', 'down', 'r', 'up', 'up']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
